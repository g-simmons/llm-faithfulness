{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-25 11:42:20.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mowain_app.catalog\u001b[0m:\u001b[36mload_task\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDataset loaded from /Users/gabe/notes/Career/job_applications/Astra_Fellowship/owain_app/data/tasks/n=4/string_notation/rule0_and_rule1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': [['0011', False],\n",
       "  ['1100', True],\n",
       "  ['0001', False],\n",
       "  ['1110', True],\n",
       "  ['1101', True],\n",
       "  ['0010', False],\n",
       "  ['1111', True]],\n",
       " 'val': [['0000', False]],\n",
       " 'test': [['0111', False],\n",
       "  ['1011', False],\n",
       "  ['1001', False],\n",
       "  ['1010', False],\n",
       "  ['0101', False],\n",
       "  ['0100', False],\n",
       "  ['0110', False],\n",
       "  ['1000', False]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from owain_app.catalog import Catalog\n",
    "\n",
    "cat = Catalog()\n",
    "cat.load_task(rule_names=[\"rule0\",\"rule1\"],num_rules=4,notation_type=\"string_notation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the unlabeled example from the labeled examples. Respond with a single binary digit indicating the label.\n",
      "\n",
      "Labeled Examples:\n",
      "```\n",
      "input: 0000; label: 0\n",
      "input: 0001; label: 1\n",
      "```\n",
      "\n",
      "Unlabeled Example:\n",
      "```\n",
      "input: 0010; label: \n"
     ]
    }
   ],
   "source": [
    "# from owain_app.schemas import BinaryString, Label\n",
    "from typing import List, Tuple\n",
    "\n",
    "EXAMPLE_TEMPlATE = \"input: {input}; label: {label}\"\n",
    "INSTRUCTIONS = \"Classify the unlabeled example from the labeled examples. Respond with a single binary digit indicating the label.\"\n",
    "\n",
    "def make_prompt(train_examples: List[Tuple], test_example: str, example_template: str = EXAMPLE_TEMPlATE, instructions: str = INSTRUCTIONS):\n",
    "    example_content = [example_template.format(input=x, label=y) for x,y in train_examples]\n",
    "    example_content = \"\\n\".join(example_content)\n",
    "    test_content = example_template.format(input=test_example, label=\"\")\n",
    "\n",
    "    return instructions + \"\\n\\nLabeled Examples:\\n```\\n\" + example_content + \"\\n```\\n\\nUnlabeled Example:\\n```\\n\" + test_content\n",
    "print(make_prompt([(\"0000\", \"0\"), (\"0001\", \"1\")], \"0010\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>train_examples</th>\n",
       "      <th>test_example</th>\n",
       "      <th>rule_names</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0100</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0110</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1001</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1010</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0111</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0101</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1011</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0000</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1000</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Classify the unlabeled example from the labele...   \n",
       "1  Classify the unlabeled example from the labele...   \n",
       "2  Classify the unlabeled example from the labele...   \n",
       "3  Classify the unlabeled example from the labele...   \n",
       "4  Classify the unlabeled example from the labele...   \n",
       "5  Classify the unlabeled example from the labele...   \n",
       "6  Classify the unlabeled example from the labele...   \n",
       "7  Classify the unlabeled example from the labele...   \n",
       "8  Classify the unlabeled example from the labele...   \n",
       "\n",
       "                                      train_examples test_example  \\\n",
       "0  [[0011, False], [1100, True], [0001, False], [...         0100   \n",
       "1  [[0011, False], [1100, True], [0001, False], [...         0110   \n",
       "2  [[0011, False], [1100, True], [0001, False], [...         1001   \n",
       "3  [[0011, False], [1100, True], [0001, False], [...         1010   \n",
       "4  [[0011, False], [1100, True], [0001, False], [...         0111   \n",
       "5  [[0011, False], [1100, True], [0001, False], [...         0101   \n",
       "6  [[0011, False], [1100, True], [0001, False], [...         1011   \n",
       "7  [[0011, False], [1100, True], [0001, False], [...         0000   \n",
       "8  [[0011, False], [1100, True], [0001, False], [...         1000   \n",
       "\n",
       "       rule_names split  label  \n",
       "0  [rule0, rule1]  test   None  \n",
       "1  [rule0, rule1]  test   None  \n",
       "2  [rule0, rule1]  test   None  \n",
       "3  [rule0, rule1]  test   None  \n",
       "4  [rule0, rule1]  test   None  \n",
       "5  [rule0, rule1]  test   None  \n",
       "6  [rule0, rule1]  test   None  \n",
       "7  [rule0, rule1]   val  False  \n",
       "8  [rule0, rule1]  test   None  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(data[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owain_app.catalog import Catalog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import jsonlines\n",
    "\n",
    "catalog = Catalog()\n",
    "\n",
    "\n",
    "def get_feature_columns(predictions_df):\n",
    "    columns = [\n",
    "        f\"x{i+1}\" for i in range(0, len(predictions_df[\"test_example\"].values[0]))\n",
    "    ]\n",
    "    return columns\n",
    "\n",
    "\n",
    "def normalize_predictions(data):\n",
    "    responses = pd.json_normalize(data[\"response\"])\n",
    "    choices = pd.json_normalize(responses[\"choices\"].apply(lambda x: x[0]))\n",
    "    predictions = (\n",
    "        choices[\"message.content\"].map({\"True\": \"1\", \"False\": \"0\"}).rename(\"prediction\")\n",
    "    )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def normalize_prompt(data):\n",
    "    return pd.json_normalize(data[\"prompt\"])\n",
    "\n",
    "\n",
    "def get_train_correlations(predictions_df):\n",
    "    \"A sanity check to see which features are correlated with the label in the training set\"\n",
    "    train_df = pd.DataFrame(predictions_df[\"train_examples\"][0])\n",
    "    train_df_ = pd.DataFrame(\n",
    "        train_df[0].apply(lambda x: list(x)).values.tolist(),\n",
    "        columns=[\"x1\", \"x2\", \"x3\", \"x4\"],\n",
    "    )\n",
    "    train_df_[\"label\"] = train_df[1].map({True: \"1\", False: \"0\"})\n",
    "    train_correlations = train_df_.corr()[\"label\"].round(2).sort_values(ascending=False)\n",
    "\n",
    "    return train_correlations\n",
    "\n",
    "def compute_val_accuracy(predictions_df):\n",
    "    val_accuracy_n = len(predictions_df[predictions_df.split == \"val\"])\n",
    "\n",
    "    val_accuracy_score = accuracy_score(\n",
    "        predictions_df[predictions_df.split == \"val\"][\"label\"],\n",
    "        predictions_df[predictions_df.split == \"val\"][\"message.content\"],\n",
    "    )\n",
    "    return val_accuracy_score, val_accuracy_n\n",
    "\n",
    "def compute_accuracy_and_learned_rules():\n",
    "    # read the data\n",
    "    data_path = catalog.data_path / \"model_responses_icl/n=4/rule0_and_rule1/all.jsonl\"\n",
    "    with jsonlines.open(data_path) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "\n",
    "    # convert to dataframe\n",
    "    data = pd.DataFrame(data, columns=[\"input\", \"response\", \"prompt\"])\n",
    "\n",
    "    predictions = normalize_predictions(data)\n",
    "    prompt = normalize_prompt(data)\n",
    "\n",
    "    predictions_df = pd.concat([prompt, predictions], axis=1)\n",
    "    predictions_df[\"label\"] = predictions_df[\"label\"].map(\n",
    "        {True: \"1\", False: \"0\", None: np.nan}\n",
    "    )\n",
    "    \n",
    "    train_correlations = get_train_correlations(predictions_df)\n",
    "\n",
    "    features = pd.DataFrame(\n",
    "        predictions_df[\"test_example\"].apply(lambda x: list(x)).values.tolist(),\n",
    "        columns=columns,\n",
    "    )\n",
    "\n",
    "    columns = get_feature_columns(predictions_df)\n",
    "\n",
    "    predictions_df_cat = pd.concat([features, predictions_df[\"message.content\"]], axis=1)\n",
    "\n",
    "    # get correlations between features and predictions\n",
    "    feature_correlations = predictions_df_cat.corr()[\"prediction\"].round(2).sort_values(ascending=False)\n",
    "\n",
    "    \n",
    "    val_accuracy_score, val_accuracy_n = compute_val_accuracy(predictions_df)\n",
    "\n",
    "    return {\n",
    "        \"val_accuracy_score\": val_accuracy_score,\n",
    "        \"val_accuracy_n\": val_accuracy_n,\n",
    "        \"feature_correlations\": feature_correlations,\n",
    "        \"train_correlations\": train_correlations,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1       1.00\n",
       "x2       1.00\n",
       "label    1.00\n",
       "x3      -0.17\n",
       "x4      -0.17\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>train_examples</th>\n",
       "      <th>test_example</th>\n",
       "      <th>rule_names</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>message.content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0100</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0110</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1001</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1010</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0111</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0101</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1011</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>0000</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Classify the unlabeled example from the labele...</td>\n",
       "      <td>[[0011, False], [1100, True], [0001, False], [...</td>\n",
       "      <td>1000</td>\n",
       "      <td>[rule0, rule1]</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Classify the unlabeled example from the labele...   \n",
       "1  Classify the unlabeled example from the labele...   \n",
       "2  Classify the unlabeled example from the labele...   \n",
       "3  Classify the unlabeled example from the labele...   \n",
       "4  Classify the unlabeled example from the labele...   \n",
       "5  Classify the unlabeled example from the labele...   \n",
       "6  Classify the unlabeled example from the labele...   \n",
       "7  Classify the unlabeled example from the labele...   \n",
       "8  Classify the unlabeled example from the labele...   \n",
       "\n",
       "                                      train_examples test_example  \\\n",
       "0  [[0011, False], [1100, True], [0001, False], [...         0100   \n",
       "1  [[0011, False], [1100, True], [0001, False], [...         0110   \n",
       "2  [[0011, False], [1100, True], [0001, False], [...         1001   \n",
       "3  [[0011, False], [1100, True], [0001, False], [...         1010   \n",
       "4  [[0011, False], [1100, True], [0001, False], [...         0111   \n",
       "5  [[0011, False], [1100, True], [0001, False], [...         0101   \n",
       "6  [[0011, False], [1100, True], [0001, False], [...         1011   \n",
       "7  [[0011, False], [1100, True], [0001, False], [...         0000   \n",
       "8  [[0011, False], [1100, True], [0001, False], [...         1000   \n",
       "\n",
       "       rule_names split label message.content  \n",
       "0  [rule0, rule1]  test   NaN               0  \n",
       "1  [rule0, rule1]  test   NaN               0  \n",
       "2  [rule0, rule1]  test   NaN               1  \n",
       "3  [rule0, rule1]  test   NaN               0  \n",
       "4  [rule0, rule1]  test   NaN               1  \n",
       "5  [rule0, rule1]  test   NaN               0  \n",
       "6  [rule0, rule1]  test   NaN               1  \n",
       "7  [rule0, rule1]   val     0               0  \n",
       "8  [rule0, rule1]  test   NaN               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mft_textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
